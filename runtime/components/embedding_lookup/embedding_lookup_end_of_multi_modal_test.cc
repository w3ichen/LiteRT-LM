// Copyright 2025 The ODML Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include "runtime/components/embedding_lookup/embedding_lookup_end_of_multi_modal.h"

#include <cstddef>
#include <cstdint>
#include <cstring>
#include <filesystem>  // NOLINT: Required for path manipulation.
#include <memory>
#include <optional>
#include <utility>
#include <vector>

#include <gmock/gmock.h>
#include <gtest/gtest.h>
#include "absl/status/status.h"  // from @com_google_absl
#include "absl/types/span.h"  // from @com_google_absl
#include "litert/cc/litert_element_type.h"  // from @litert
#include "litert/cc/litert_environment.h"  // from @litert
#include "litert/cc/litert_expected.h"  // from @litert
#include "litert/cc/litert_layout.h"  // from @litert
#include "litert/cc/litert_macros.h"  // from @litert
#include "litert/cc/litert_model.h"  // from @litert
#include "litert/cc/litert_tensor_buffer.h"  // from @litert
#include "litert/test/matchers.h"  // from @litert

namespace litert::lm {

constexpr char kTestdataDir[] =
    "litert_lm/runtime/components/testdata/";

// These tests are currently disabled because the LiteRT does not
// support the end of multi-modal embedding model at the moment. The model
// is quite unusual because it is just a single constant op. However, the
// issue is not limited to the test model because the real end of multi-modal
// embedding model is also a single constant op.
class EndOfMultiModalEmbeddingTest : public testing::Test {
 protected:
  absl::Status CreateModelFromFile() {
    // The model is a dummy end of multi-modal embedding model that has no
    // input and returns a fixed embedding tensor. It returns a tensor of the
    // shape [1, 1, 4, 32]. The values in the table are generated by the
    // following formula:
    // for v in range(vocab_size):
    //   for t in range(token):
    //     for n in range(num_head):
    //       for d in range(dim):
    //         tensor[v, t, n, d] = (d + n * 100 + t * 1000 + v * 10000) * 2

    auto model_path = std::filesystem::path(::testing::SrcDir()) /
                      kTestdataDir / "dummy_end_of_multi_modal_model.tflite";
    LITERT_ASSIGN_OR_RETURN(model_, Model::CreateFromFile(model_path.string()));
    return absl::OkStatus();
  }

  Expected<TensorBuffer> GetTensorBuffer(Dimensions& dimensions) {
    LITERT_ASSIGN_OR_RETURN(auto env, ::litert::Environment::Create({}));
    size_t buffer_size = sizeof(float);
    for (auto dim : dimensions) {
      buffer_size *= dim;
    }
    Layout layout(dimensions);
    RankedTensorType ranked_tensor_type(ElementType::Float32,
                                        std::move(layout));

    LITERT_ASSIGN_OR_RETURN(auto buffer,
                            TensorBuffer::CreateManaged(
                                env.Get(), kLiteRtTensorBufferTypeHostMemory,
                                ranked_tensor_type, buffer_size));
    // Clear the buffer to 0.
    auto buffer_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        buffer, ::litert::TensorBuffer::LockMode::kRead);
    auto output_tensor_ptr =
        reinterpret_cast<float*>(buffer_lock_and_addr->second);
    memset(output_tensor_ptr, 0, buffer_size);

    return buffer;
  }

  std::unique_ptr<EndOfMultiModalEmbedding> GetEndOfMultiModalEmbedding() {
    if (!CreateModelFromFile().ok()) {
      return nullptr;
    }
    if (!model_.has_value()) {
      return nullptr;
    }
    auto status = EndOfMultiModalEmbedding::Create(&*model_, special_token_);
    if (!status.ok()) {
      return nullptr;
    }
    return std::move(status.value());
  }

  int special_token_ = -3;
  std::optional<Model> model_;
};

TEST_F(EndOfMultiModalEmbeddingTest, LookupDecodeVector) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  std::vector<float> output_vector(4 * 32);

  int32_t token = -3;
  ASSERT_THAT(embedding->LookupDecode(token, output_vector),
              testing::status::StatusIs(
                  absl::StatusCode::kUnimplemented,
                  testing::HasSubstr("LookupDecode is not implemented for "
                                     "EndOfMultiModalEmbedding.")));
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupDecode) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 1, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  int32_t token = -3;
  ASSERT_THAT(
      embedding->LookupDecode(token, &output_tensor),
      testing::status::StatusIs(
          absl::StatusCode::kUnimplemented,
          testing::HasSubstr(
              "LookupDecode is not implemented for EndOfMultiModalEmbedding")));
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupPrefillVector) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  std::vector<float> output_vector(4 * 32);

  int32_t token = -3;
  ASSERT_OK(embedding->LookupPrefill(token, output_vector));

  size_t offset = 0;
  // Dimensions 0 and 1 both have size 1.
  for (int idx2 = 0; idx2 < 4; ++idx2) {
    for (int idx3 = 0; idx3 < 32; ++idx3) {
      // Dimensions 0 and 1 both have size 1 so offset and expected value can
      // ignore them.
      float expected_value = (100.0 * idx2 + idx3) * 2;
      ASSERT_NEAR(output_vector[offset++], expected_value, 1e-5);
    }
  }
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillVectorBadOutputVector) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  std::vector<float> output_vector(4 * 32 + 1);

  int32_t token = -3;
  ASSERT_THAT(embedding->LookupPrefill(token, output_vector),
              testing::status::StatusIs(
                  absl::StatusCode::kInvalidArgument,
                  testing::HasSubstr("The output vector is not the correct "
                                     "size for the end of multi-modal")));
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillVectorNonSpecialToken) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  std::vector<float> output_vector(4 * 32);
  for (int i = 0; i < output_vector.size(); ++i) {
    output_vector[i] = 99;
  }

  int32_t token = 1;
  ASSERT_OK(embedding->LookupPrefill(token, output_vector));

  for (int i = 0; i < output_vector.size(); ++i) {
    ASSERT_EQ(output_vector[i], 99);
  }
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupPrefill) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));
  {
    auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
    auto output_tensor_ptr =
        reinterpret_cast<float*>(output_tensor_lock_and_addr->second);
    LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size,
                                output_tensor.Size());
    for (int i = 0; i < output_tensor_size / sizeof(float); ++i) {
      output_tensor_ptr[i] = 99;
    }
  }

  std::vector<int> tokens = {-3, 2, -3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_OK(embedding->LookupPrefill(tokens_span, &output_tensor, 0));

  auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
      output_tensor, ::litert::TensorBuffer::LockMode::kRead);
  auto output_tensor_ptr =
      reinterpret_cast<float*>(output_tensor_lock_and_addr->second);

  for (int idx0 = 0; idx0 < tokens.size(); ++idx0) {
    int token = tokens[idx0];
    for (int idx2 = 0; idx2 < dimensions[2]; ++idx2) {
      for (int idx3 = 0; idx3 < dimensions[3]; ++idx3) {
        // Since dimension 1 is of size 1, the offset and expected value can
        // ignore it.
        size_t offset =
            idx0 * dimensions[2] * dimensions[3] + idx2 * dimensions[3] + idx3;
        float expected_value = 99;
        if (token == -3) {
          expected_value = (100.0 * idx2 + idx3) * 2;
        }
        ASSERT_NEAR(output_tensor_ptr[offset], expected_value, 1e-5);
      }
    }
  }
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupAllSpecialTokens) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));
  {
    auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
    auto output_tensor_ptr =
        reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);
    LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size,
                                output_tensor.Size());
    for (int i = 0; i < output_tensor_size / sizeof(float); ++i) {
      output_tensor_ptr[i] = 99;
    }
  }

  std::vector<int> tokens = {-3, -3, -3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_OK(embedding->LookupPrefill(tokens_span, &output_tensor, 0));

  auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
      output_tensor, ::litert::TensorBuffer::LockMode::kRead);
  auto output_tensor_ptr =
      reinterpret_cast<float*>(output_tensor_lock_and_addr->second);

  for (int idx0 = 0; idx0 < tokens.size(); ++idx0) {
    for (int idx2 = 0; idx2 < dimensions[2]; ++idx2) {
      for (int idx3 = 0; idx3 < dimensions[3]; ++idx3) {
        // Since dimension 1 is of size 1, the offset and expected value can
        // ignore it.
        size_t offset =
            idx0 * dimensions[2] * dimensions[3] + idx2 * dimensions[3] + idx3;
        float expected_value = (100.0 * idx2 + idx3) * 2;
        ASSERT_NEAR(output_tensor_ptr[offset], expected_value, 1e-5);
      }
    }
  }
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupNoSpecialTokens) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));
  {
    auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
    auto output_tensor_ptr =
        reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);
    LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size,
                                output_tensor.Size());
    for (int i = 0; i < output_tensor_size / sizeof(float); ++i) {
      output_tensor_ptr[i] = 99;
    }
  }

  std::vector<int> tokens = {1, 2, 3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_OK(embedding->LookupPrefill(tokens_span, &output_tensor, 0));

  auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
      output_tensor, ::litert::TensorBuffer::LockMode::kRead);
  auto output_tensor_ptr =
      reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);

  LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size, output_tensor.Size());
  for (int i = 0; i < output_tensor_size / sizeof(float); ++i) {
    ASSERT_EQ(output_tensor_ptr[i], 99);
  }
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillBadOutputTensorDimNum) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  std::vector<int> tokens = {1, 2, 3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_THAT(embedding->LookupPrefill(tokens_span, &output_tensor, 0),
              testing::status::StatusIs(
                  absl::StatusCode::kInvalidArgument,
                  testing::HasSubstr(
                      "The output tensor from the EndOfMultiModalEmbedding "
                      "model must be have the same number of dimensions")));
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillBadOutputTensorDimSize) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4, 256});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  std::vector<int> tokens = {1, 2, 3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_THAT(embedding->LookupPrefill(tokens_span, &output_tensor, 0),
              testing::status::StatusIs(
                  absl::StatusCode::kInvalidArgument,
                  testing::HasSubstr(
                      "The output tensor from the EndOfMultiModalEmbedding "
                      "model must be have the same dimensions")));
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillBadOutputTensorDim0) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({3, 1, 4, 256});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  std::vector<int> tokens = {1, 2, 3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_THAT(
      embedding->LookupPrefill(tokens_span, &output_tensor, 0),
      testing::status::StatusIs(
          absl::StatusCode::kUnimplemented,
          testing::HasSubstr(
              "The output tensor to fill from the EndOfMultiModalEmbedding "
              "model must be have the 0th dimension as 1.")));
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillBadOutputTensorDim1) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 1, 4, 256});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  std::vector<int> tokens = {1, 2, 3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_THAT(
      embedding->LookupPrefill(tokens_span, &output_tensor, 0),
      testing::status::StatusIs(
          absl::StatusCode::kInvalidArgument,
          testing::HasSubstr(
              "The output tensor to fill from the EndOfMultiModalEmbedding "
              "model must have a 1st dimension that is at least "
              "the same size as the number of tokens")));
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupPrefillLargerOutputTensor) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 4, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));
  {
    auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
    auto output_tensor_ptr =
        reinterpret_cast<float*>(output_tensor_lock_and_addr->second);
    LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size,
                                output_tensor.Size());
    for (int i = 0; i < output_tensor_size / sizeof(float); ++i) {
      output_tensor_ptr[i] = 99;
    }
  }

  std::vector<int> tokens = {1, -3, 3};
  absl::Span<const int> tokens_span(tokens);
  ASSERT_OK(embedding->LookupPrefill(tokens_span, &output_tensor, 0));

  auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
      output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
  auto output_tensor_ptr =
      reinterpret_cast<float*>(output_tensor_lock_and_addr->second);

  for (int idx0 = 0; idx0 < tokens.size() + 1; ++idx0) {
    int token = 0;
    if (idx0 < tokens.size()) {
      token = tokens[idx0];
    }
    for (int idx2 = 0; idx2 < dimensions[2]; ++idx2) {
      for (int idx3 = 0; idx3 < dimensions[3]; ++idx3) {
        // Since dimension 1 is of size 1, the offset and expected value can
        // ignore it.
        size_t offset =
            idx0 * dimensions[2] * dimensions[3] + idx2 * dimensions[3] + idx3;
        float expected_value = 99;
        if (token == -3) {
          expected_value = (100.0 * idx2 + idx3) * 2;
        }
        ASSERT_NEAR(output_tensor_ptr[offset], expected_value, 1e-5);
      }
    }
  }
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupPrefillNullOutputTensor) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  std::vector<int> tokens = {1, -3, 3};
  ASSERT_THAT(
      embedding->LookupPrefill(tokens, nullptr, 0),
      testing::status::StatusIs(absl::StatusCode::kInvalidArgument,
                                testing::HasSubstr("Output tensor is null")));
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupPrefillWithOffset) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  {
    auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
    auto output_tensor_ptr =
        reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);
    LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size,
                                output_tensor.Size());
    memset(output_tensor_ptr, 99, output_tensor_size);
  }

  std::vector<int> tokens = {-3, -3};
  absl::Span<const int> tokens_span(tokens);
  const size_t float_offset = 4 * 32;
  const size_t byte_offset = float_offset * sizeof(float);

  ASSERT_OK(embedding->LookupPrefill(tokens_span, &output_tensor, byte_offset));

  auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
      output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
  auto output_tensor_ptr =
      reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);
  for (int i = 0; i < byte_offset; ++i) {
    ASSERT_EQ(output_tensor_ptr[i], 99);
  }

  auto output_tensor_ptr_float =
      reinterpret_cast<float*>(output_tensor_lock_and_addr->second);

  for (int idx0 = 0; idx0 < tokens.size(); ++idx0) {
    for (int idx2 = 0; idx2 < dimensions[2]; ++idx2) {
      for (int idx3 = 0; idx3 < dimensions[3]; ++idx3) {
        // Since dimension 1 is of size 1, the offset and expected value can
        // ignore it.
        size_t offset = float_offset + idx0 * dimensions[2] * dimensions[3] +
                        idx2 * dimensions[3] + idx3;
        float expected_value = (100.0 * idx2 + idx3) * 2;
        ASSERT_NEAR(output_tensor_ptr_float[offset], expected_value, 1e-5);
      }
    }
  }
}

TEST_F(EndOfMultiModalEmbeddingTest,
       LookupPrefillWithOffsetAndFewerTokensThanOutputTensor) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 3, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));
  {
    auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
        output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
    auto output_tensor_ptr =
        reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);
    LITERT_ASSERT_OK_AND_ASSIGN(size_t output_tensor_size,
                                output_tensor.Size());
    memset(output_tensor_ptr, 99, output_tensor_size);
  }

  std::vector<int> tokens = {-3};
  absl::Span<const int> tokens_span(tokens);
  const size_t float_offset = 4 * 32;
  const size_t byte_offset = float_offset * sizeof(float);

  ASSERT_OK(embedding->LookupPrefill(tokens_span, &output_tensor, byte_offset));

  auto output_tensor_lock_and_addr = ::litert::TensorBufferScopedLock::Create(
      output_tensor, ::litert::TensorBuffer::LockMode::kWrite);
  auto output_tensor_ptr =
      reinterpret_cast<uint8_t*>(output_tensor_lock_and_addr->second);

  // Check that the first token is not overwritten.
  for (int i = 0; i < byte_offset; ++i) {
    ASSERT_EQ(output_tensor_ptr[i], 99);
  }

  // Check that the last token is not overwritten.
  for (int i = byte_offset * 2; i < byte_offset * 3; ++i) {
    ASSERT_EQ(output_tensor_ptr[i], 99);
  }

  auto output_tensor_ptr_float =
      reinterpret_cast<float*>(output_tensor_lock_and_addr->second);

  for (int idx0 = 0; idx0 < tokens.size(); ++idx0) {
    for (int idx2 = 0; idx2 < dimensions[2]; ++idx2) {
      for (int idx3 = 0; idx3 < dimensions[3]; ++idx3) {
        // Since dimension 1 is of size 1, the offset and expected value can
        // ignore it.
        size_t offset = float_offset + idx0 * dimensions[2] * dimensions[3] +
                        idx2 * dimensions[3] + idx3;
        float expected_value = (100.0 * idx2 + idx3) * 2;
        ASSERT_NEAR(output_tensor_ptr_float[offset], expected_value, 1e-5);
      }
    }
  }
}

TEST_F(EndOfMultiModalEmbeddingTest, LookupPrefillWithBadOffset) {
  std::unique_ptr<EndOfMultiModalEmbedding> embedding =
      GetEndOfMultiModalEmbedding();
  ASSERT_NE(embedding, nullptr);

  Dimensions dimensions({1, 2, 4, 32});
  LITERT_ASSERT_OK_AND_ASSIGN(TensorBuffer output_tensor,
                              GetTensorBuffer(dimensions));

  std::vector<int> tokens = {1, -3};
  absl::Span<const int> tokens_span(tokens);
  const size_t float_offset = 4 * 32;
  const size_t byte_offset = float_offset * sizeof(float);

  ASSERT_THAT(
      embedding->LookupPrefill(tokens_span, &output_tensor, byte_offset),
      testing::status::StatusIs(
          absl::StatusCode::kInvalidArgument,
          testing::HasSubstr(
              "The byte offset and the total number of bytes to be written "
              "must not exceed the size of the output tensor")));
}

}  // namespace litert::lm
