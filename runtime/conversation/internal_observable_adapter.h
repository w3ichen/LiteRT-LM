// Copyright 2025 The ODML Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef THIRD_PARTY_ODML_LITERT_LM_RUNTIME_CONVERSATION_INTERNAL_OBSERVABLE_ADAPTER_H_
#define THIRD_PARTY_ODML_LITERT_LM_RUNTIME_CONVERSATION_INTERNAL_OBSERVABLE_ADAPTER_H_

#include <cstddef>
#include <functional>
#include <memory>
#include <string>

#include "absl/base/nullability.h"  // from @com_google_absl
#include "absl/status/status.h"  // from @com_google_absl
#include "absl/strings/string_view.h"  // from @com_google_absl
#include "runtime/conversation/io_types.h"
#include "runtime/conversation/model_data_processor/config_registry.h"
#include "runtime/conversation/model_data_processor/model_data_processor.h"
#include "runtime/engine/io_types.h"

namespace litert::lm {

// An adapter to wrap a `MessageObservable` in an `InferenceObservable`.
//
// An `InferenceObservable` asynchronously receives responses (i.e. tokens)
// from the `Session` as output is generated by the model.
//
// A `MessageObservable` asynchronously receives messages from a `Conversation`.
// A message represents a turn or a part of a turn in a conversation between the
// user and the model. A message is composed from one or more tokens and
// contains metadata such as the role (e.g. "user", "assistant") and type (e.g.
// "text", "tool_call") of the message.
class InternalObservableAdapter : public InferenceObservable {
 public:
  using CompleteMessageCallback = std::function<void(const Message& message)>;

  // Creates an instance of `InternalObservableAdapter`.
  //
  // - `model_data_processor` processes the input and output of the model.
  // - `user_observer` is the `MessageObservable` defined by the user to receive
  //    messages from the `Conversation`.
  // - `processor_args` is the set of arguments to pass to the
  //   `ModelDataProcessor`.
  static std::unique_ptr<InternalObservableAdapter> Create(
      ModelDataProcessor* model_data_processor,
      MessageObservable* user_observer, DataProcessorArguments processor_args);

  // Sets a callback to be called with the complete message when inference has
  // finished successfully.
  void SetCompleteMessageCallback(
      CompleteMessageCallback complete_message_callback);

  // Called when a new response is generated.
  void OnNext(const Responses& responses) override;

  // Called when inference has successfully finished.
  void OnDone() override;

  // Called when an error is encountered during inference.
  void OnError(const absl::Status& status) override;

 private:
  explicit InternalObservableAdapter(ModelDataProcessor* model_data_processor,
                                     MessageObservable* user_observer,
                                     DataProcessorArguments processor_args);

  void SendMessage(absl::string_view text);

  absl::Status ProcessResponseText(absl::string_view response_text);

  ModelDataProcessor* absl_nonnull model_data_processor_;
  MessageObservable* absl_nonnull user_observer_;
  CompleteMessageCallback complete_message_callback_;
  DataProcessorArguments processor_args_;
  std::string accumulated_response_text_;
  size_t cursor_ = 0;
  bool inside_tool_call_ = false;
};

}  // namespace litert::lm

#endif  // THIRD_PARTY_ODML_LITERT_LM_RUNTIME_CONVERSATION_INTERNAL_OBSERVABLE_ADAPTER_H_
